# Бенчмарк Structured Output LLM (OpenRouter)

Репозиторий содержит скрипт для тестирования и сравнения LLM по способности извлекать и возвращать структурированные данные (JSON) из неструктурированного текста.

Проект использует **@instructor-ai/instructor** совместно с **Zod** для надежного типизированного вывода и **OpenRouter.ai** для доступа к множеству моделей от разных провайдеров.

- Ключевые файлы:
  - Точка входа: [main.ts](main.ts)
  - Тестовые кейсы: [testCases.ts](testCases.ts)
  - Пример переменных окружения: [example.env](example.env)

## 🚀 Возможности

- Сравнение моделей: Быстро тестируйте и сравнивайте много моделей (OpenAI, Google, Anthropic, Mistral, Groq и т.д.) через единый API (OpenRouter).
- Надежный парсинг: Валидный JSON обеспечивается связкой Instructor + Zod. Если модель вернула невалидные данные, Instructor попытается их исправить.
- Разнообразный набор тестов: Простые и сложные кейсы, неполные данные, опечатки, косвенные указания, несколько языков и пр.
- Аналитика производительности и стоимости: Замер времени выполнения, учет токенов (если доступны) и расчет примерной стоимости на основе заданных тарифов.
- Гибкая конфигурация: Легко добавляйте модели/провайдеров/кейсы и настраивайте параметры запросов.
- Отказоустойчивость: Таймауты и ретраи для обработки медленных/нестабильных ответов API.

## ⚙️ Как это работает

1. Конфигурация: Список моделей, провайдеров и их цены описаны в [main.ts](main.ts).
2. Схема данных: Zod-схема в [main.ts](main.ts) описывает целевой формат JSON.
3. Тестовый набор: Массив кейсов находится в [testCases.ts](testCases.ts). Каждый кейс включает:
   - description — описание цели теста
   - content — входной неструктурированный текст
   - validator — функция для проверки семантической корректности результата
4. Выполнение: Для каждой заданной модели запускается весь тестовый набор.
5. Вызов LLM: Текст передается в поле сообщения пользователя, а Zod-схема — как ожидаемый формат ответа. Instructor добавляет системный промпт, чтобы модель следовала схеме.
6. Валидация и метрики:
   - Ответ валидируется по Zod-схеме.
   - Дополнительно validator проверяет смысловую корректность.
   - Сбор метрик: время, токены и статус (успех, ошибка валидации, сбой).
7. Отчет: По завершении — сводная таблица с результатами для удобного сравнения.

## 🛠️ Технологии

- TypeScript
- Node.js
- OpenAI SDK (используется как клиент для OpenRouter)
- @instructor-ai/instructor
- Zod
- OpenRouter.ai
- p-limit
- dotenv

## 📦 Установка

1) Клонируйте репозиторий
```bash
git clone https://github.com/x0rium/llm-structured-output-benchmark.git
cd llm-structured-output-benchmark
```

2) Установите зависимости (рекомендуется PNPM, lockfile присутствует)
```bash
pnpm install
# или
npm install
# или
yarn install
```

3) Настройте переменные окружения

Создайте файл `.env` в корне, ориентируясь на [example.env](example.env):
```env
OPENROUTER_KEY=sk-or-...
BASE_URI=https://openrouter.ai/api/v1
```

- Получить ключ: https://openrouter.ai
- По умолчанию используется официальный BASE_URI OpenRouter.

## ▶️ Запуск

Через скрипты пакета:
```bash
pnpm start
# или
npm run start
# или
yarn start
```

Напрямую через tsx:
```bash
npx tsx main.ts
```

В консоли вы увидите прогресс по моделям и финальную сводную таблицу.

## 🔧 Конфигурация

- Добавить/изменить модели/провайдеров/цены:
  - Откройте [main.ts](main.ts) и расширьте список `modelProviderCombinations`.
- Изменить целевой JSON:
  - Обновите Zod-схему в [main.ts](main.ts) под вашу структуру.
- Добавить новые кейсы:
  - Дополните массив `testCases` в [testCases.ts](testCases.ts), добавив объект с `description`, `content` и (опционально) `validator`.

## 🧪 Пример вывода

```
🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆
🏆      ФИНАЛЬНЫЙ ОТЧЕТ БЕНЧМАРКА      🏆
🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆
┌─────────┬───────────────────────────────────────────┬────────────────────────┬─────────────┬────────────────┬───────────────────┬────────────┐
│ (index) │                   Model                   │        Provider        │ Success (%) │ Avg Time (sec) │ Results (✅/⚠️/❌) │  Cost ($)  │
├─────────┼───────────────────────────────────────────┼────────────────────────┼─────────────┼────────────────┼───────────────────┼────────────┤
│    0    │       'openrouter/z-ai/glm-4.5-air'       │       'GMICloud'       │   '75.0%'   │     '2.97'     │     '15/5/0'      │ '0.003447' │
│    1    │      'openrouter/openai/gpt-5-nano'       │       'Default'        │  '100.0%'   │     '9.25'     │     '20/0/0'      │ '0.008692' │
│    2    │      'openrouter/openai/gpt-5-mini'       │       'Default'        │   '95.0%'   │     '6.56'     │     '19/1/0'      │ '0.002268' │
│    3    │      'openrouter/openai/gpt-oss-20b'      │         'groq'         │   '95.0%'   │     '1.41'     │     '19/1/0'      │ '0.003606' │
│    4    │     'openrouter/openai/gpt-oss-120b'      │         'groq'         │   '85.0%'   │     '1.81'     │     '17/3/0'      │ '0.006469' │
│    5    │ 'openrouter/google/gemini-2.5-flash-lite' │    'google-vertex'     │   '75.0%'   │     '3.71'     │     '15/5/0'      │ '0.001439' │
│    6    │   'openrouter/google/gemini-2.5-flash'    │ 'google-vertex/global' │   '95.0%'   │     '3.06'     │     '19/1/0'      │ '0.006410' │
│    7    │       'openrouter/x-ai/grok-3-mini'       │         'xai'          │   '65.0%'   │     '8.26'     │     '13/7/0'      │ '0.009828' │
│    8    │  'openrouter/deepseek/deepseek-r1-0528'   │      'targon/fp8'      │   '90.0%'   │     '3.28'     │     '18/2/0'      │ '0.008347' │
│    9    │     'openrouter/qwen/qwen3-235b-a22b'     │    'deepinfra/fp8'     │   '90.0%'   │     '2.99'     │     '18/2/0'      │ '0.006320' │
│   10    │         'openrouter/qwen/qwq-32b'         │      'deepinfra'       │   '90.0%'   │     '2.86'     │     '18/2/0'      │ '0.000828' │
└─────────┴───────────────────────────────────────────┴────────────────────────┴─────────────┴────────────────┴───────────────────┴────────────┘
```

Примечание: точные значения зависят от окружения и выбранных моделей/провайдеров.

## 📚 Заметки

- Текущие тестовые кейсы в [testCases.ts](testCases.ts) — на русском языке. Промпт в [main.ts](main.ts) — на английском, это нормально: модели корректно извлекают данные и выдают JSON по схеме.
- Учет токенов и стоимость — приблизительные. Если API возвращает usage, он учитывается; иначе стоимость может быть нулевой.

## 📄 Лицензия

Проект распространяется по лицензии MIT. См. файл [LICENSE](LICENSE).

## 🇬🇧 English README

Доступна английская версия: [README.md](README.md).