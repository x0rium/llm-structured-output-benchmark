# Бенчмарк Structured Output LLM (OpenRouter)

Репозиторий содержит скрипт для тестирования и сравнения LLM по способности извлекать и возвращать структурированные данные (JSON) из неструктурированного текста.

Проект использует **@instructor-ai/instructor** совместно с **Zod** для надежного типизированного вывода и **OpenRouter.ai** для доступа к множеству моделей от разных провайдеров.

- Ключевые файлы:
  - Точка входа: [main.ts](main.ts)
  - Тестовые кейсы: [testCases.ts](testCases.ts)
  - Пример переменных окружения: [example.env](example.env)

## 🚀 Возможности

- Сравнение моделей: Быстро тестируйте и сравнивайте много моделей (OpenAI, Google, Anthropic, Mistral, Groq и т.д.) через единый API (OpenRouter).
- Надежный парсинг: Валидный JSON обеспечивается связкой Instructor + Zod. Если модель вернула невалидные данные, Instructor попытается их исправить.
- Разнообразный набор тестов: Простые и сложные кейсы, неполные данные, опечатки, косвенные указания, несколько языков и пр.
- Аналитика производительности и стоимости: Замер времени выполнения, учет токенов (если доступны) и расчет примерной стоимости на основе заданных тарифов.
- Гибкая конфигурация: Легко добавляйте модели/провайдеров/кейсы и настраивайте параметры запросов.
- Отказоустойчивость: Таймауты и ретраи для обработки медленных/нестабильных ответов API.

## ⚙️ Как это работает

1. Конфигурация: Список моделей, провайдеров и их цены описаны в [main.ts](main.ts).
2. Схема данных: Zod-схема в [main.ts](main.ts) описывает целевой формат JSON.
3. Тестовый набор: Массив кейсов находится в [testCases.ts](testCases.ts). Каждый кейс включает:
   - description — описание цели теста
   - content — входной неструктурированный текст
   - validator — функция для проверки семантической корректности результата
4. Выполнение: Для каждой заданной модели запускается весь тестовый набор.
5. Вызов LLM: Текст передается в поле сообщения пользователя, а Zod-схема — как ожидаемый формат ответа. Instructor добавляет системный промпт, чтобы модель следовала схеме.
6. Валидация и метрики:
   - Ответ валидируется по Zod-схеме.
   - Дополнительно validator проверяет смысловую корректность.
   - Сбор метрик: время, токены и статус (успех, ошибка валидации, сбой).
7. Отчет: По завершении — сводная таблица с результатами для удобного сравнения.

## 🛠️ Технологии

- TypeScript
- Node.js
- OpenAI SDK (используется как клиент для OpenRouter)
- @instructor-ai/instructor
- Zod
- OpenRouter.ai
- p-limit
- dotenv

## 📦 Установка

1) Клонируйте репозиторий
```bash
git clone https://github.com/x0rium/llm-structured-output-benchmark.git
cd llm-structured-output-benchmark
```

2) Установите зависимости (рекомендуется PNPM, lockfile присутствует)
```bash
pnpm install
# или
npm install
# или
yarn install
```

3) Настройте переменные окружения

Создайте файл `.env` в корне, ориентируясь на [example.env](example.env):
```env
OPENROUTER_KEY=sk-or-...
BASE_URI=https://openrouter.ai/api/v1
```

- Получить ключ: https://openrouter.ai
- По умолчанию используется официальный BASE_URI OpenRouter.

## ▶️ Запуск

Через скрипты пакета:
```bash
pnpm start
# или
npm run start
# или
yarn start
```

Напрямую через tsx:
```bash
npx tsx main.ts
```

В консоли вы увидите прогресс по моделям и финальную сводную таблицу.

## 🔧 Конфигурация

- Добавить/изменить модели/провайдеров/цены:
  - Откройте [main.ts](main.ts) и расширьте список `modelProviderCombinations`.
- Изменить целевой JSON:
  - Обновите Zod-схему в [main.ts](main.ts) под вашу структуру.
- Добавить новые кейсы:
  - Дополните массив `testCases` в [testCases.ts](testCases.ts), добавив объект с `description`, `content` и (опционально) `validator`.

## 🧪 Пример вывода

```
🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆
🏆      ФИНАЛЬНЫЙ ОТЧЕТ БЕНЧМАРКА      🏆
🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆🏆
┌──────────────────────────────────────────┬──────────────────────────┬───────────┬──────────────────────┬────────────────────────┬───────────────┐
│ Модель                                   │ Провайдер                │ Успех (%) │ Среднее время (сек)  │ Результаты (✅/⚠️/❌) │ Стоимость ($) │
├──────────────────────────────────────────┼──────────────────────────┼───────────┼──────────────────────┼────────────────────────┼───────────────┤
│ openrouter/google/gemini-2.5-flash       │ google-vertex/global     │ '95.2%'   │ '1.15'               │ '20/1/0'               │ '0.000451'    │
│ openrouter/openai/gpt-5-nano             │ Default                  │ '90.5%'   │ '0.88'               │ '19/2/0'               │ '0.000189'    │
│ openrouter/x-ai/grok-3-mini              │ xai                      │ '85.7%'   │ '1.52'               │ '18/2/1'               │ '0.000215'    │
│ openrouter/qwen/qwq-32b                  │ deepinfra                │ '76.2%'   │ '2.30'               │ '16/4/1'               │ '0.000088'    │
└──────────────────────────────────────────┴──────────────────────────┴───────────┴──────────────────────┴────────────────────────┴───────────────┘
```

Примечание: точные значения зависят от окружения и выбранных моделей/провайдеров.

## 📚 Заметки

- Текущие тестовые кейсы в [testCases.ts](testCases.ts) — на русском языке. Промпт в [main.ts](main.ts) — на английском, это нормально: модели корректно извлекают данные и выдают JSON по схеме.
- Учет токенов и стоимость — приблизительные. Если API возвращает usage, он учитывается; иначе стоимость может быть нулевой.

## 📄 Лицензия

Проект распространяется по лицензии MIT. См. файл [LICENSE](LICENSE).

## 🇬🇧 English README

Доступна английская версия: [README.md](README.md).